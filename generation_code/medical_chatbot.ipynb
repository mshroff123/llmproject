{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sacremoses\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbNZ-3Q9JxB",
        "outputId": "c1639bbf-ef04-4c33-ce68-d24f480113f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pepF5SeP8648"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import concurrent.futures\n",
        "from concurrent.futures import *\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Download expertqa from Google Drive using its ID\n",
        "file_id = '1xLToa0J8Jyee1RU_mFDlWm40SUJ89nCe'\n",
        "output_file = 'expertqa.jsonl'  # Choose the output file path\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "jPVq7qyq9lwJ",
        "outputId": "c431c98f-60ed-4ea9-b2cd-d8f36318ecda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xLToa0J8Jyee1RU_mFDlWm40SUJ89nCe\n",
            "To: /content/expertqa.jsonl\n",
            "100%|██████████| 30.1M/30.1M [00:00<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'expertqa.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_jsonl_for_fields(file_path, fields):\n",
        "    \"\"\"\n",
        "    Parses a JSONL file and returns dictionaries for specified fields.\n",
        "\n",
        "    :param file_path: Path to the JSONL file.\n",
        "    :param fields: List of fields to extract data for.\n",
        "    :return: A dictionary where each key is a field and the value is another dictionary\n",
        "             of question-answer pairs for that field.\n",
        "    \"\"\"\n",
        "    data = {field: {} for field in fields}\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            line_data = json.loads(line)\n",
        "            field = line_data.get('metadata', {}).get('field')\n",
        "            question = line_data.get('question')\n",
        "\n",
        "            for answer_key in line_data.get('answers', {}):\n",
        "                revised_answer = line_data['answers'][answer_key].get('revised_answer_string')\n",
        "                if field in fields and question and revised_answer:\n",
        "                    data[field][question] = revised_answer\n",
        "                    break # There is only one revised answer per question\n",
        "\n",
        "            if field in fields and question and revised_answer:\n",
        "                data[field][question] = revised_answer\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "YEHBgk2w9IXT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = parse_jsonl_for_fields('expertqa.jsonl', [\"Healthcare / Medicine\", \"Law\"])"
      ],
      "metadata": {
        "id": "TtPUGkk99nc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a small part of the data to verify\n",
        "for field in parsed_data:\n",
        "    print(f\"Field: {field}, Number of entries: {len(parsed_data[field])}\")\n",
        "    for question in list(parsed_data[field].keys())[:2]:  # Displaying the first two entries for brevity\n",
        "        print(f\"  Question: {question}\")\n",
        "        print(f\"  Answer: {parsed_data[field][question][:100]}...\")  # Displaying first 100 characters of answer\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya4M4nnVFQk4",
        "outputId": "c5b1d22d-9daf-4a33-b9b0-2a89153821d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Field: Healthcare / Medicine, Number of entries: 504\n",
            "  Question: What are signs and study findings that would indicate follicular lymphoma has transformed to diffuse large B-cell lymphoma?\n",
            "  Answer: Signs that might indicate a transformation of follicular lymphoma (FL) to diffuse large B-cell lymph...\n",
            "  Question: A patient with a history of heart failure now presents with newly diagnosed metastatic HER2+ breast cancer. What is her recommended first line of treatment and what additional information should be discussed with the patient given her history of heart failure?\n",
            "  Answer: According to the web search results, the recommended first line of treatment for HER2+ metastatic br...\n",
            "\n",
            "\n",
            "Field: Law, Number of entries: 103\n",
            "  Question: How will the estate of an individual who dies without a will be distributed?\n",
            "  Answer: When an individual dies without a will, their estate is distributed according to the intestacy rules...\n",
            "  Question: What are the requirements for claiming inheritance as per the Intestate Succession Act in South Africa?\n",
            "  Answer: To claim inheritance under the Intestate Succession Act in South Africa, the deceased must have been...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"Mohammed-Altaf/Medical-ChatBot\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(path)\n",
        "model = GPT2LMHeadModel.from_pretrained(path).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFfPsTM41Tte",
        "outputId": "d8962094-cabe-4429-a7f5-f8846d9a3be9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = {}\n",
        "\n",
        "prompt_input = (\n",
        "    \"The conversation between human and AI assistant.\\n\"\n",
        "    \"[|Human|] {input}\\n\"\n",
        "    \"[|AI|]\"\n",
        ")\n",
        "\n",
        "count = 0\n",
        "field_data = parsed_data['Healthcare / Medicine']\n",
        "for question, answer in field_data.items():\n",
        "    count += 1\n",
        "    if count > 379:\n",
        "      sentence = prompt_input.format_map({'input': question})\n",
        "      inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          beam_output = model.generate(**inputs,\n",
        "                                      min_new_tokens=1,\n",
        "                                      max_length=512,\n",
        "                                      num_beams=3,\n",
        "                                      repetition_penalty=1.2,\n",
        "                                      early_stopping=True,\n",
        "                                      eos_token_id=198)\n",
        "          generated_text = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
        "          response = re.search(r'\\[\\|AI\\|\\](.*?)$', generated_text, flags=re.DOTALL).group(1).strip()\n",
        "          outputs[question] = response\n",
        "\n",
        "      with open('output.json', 'a') as f:\n",
        "          json.dump({question: response}, f)\n",
        "          f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDtac9_B2DYg",
        "outputId": "ac032c14-e308-4f95-a331-1b12cb55db6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:198 for open-end generation.\n"
          ]
        }
      ]
    }
  ]
}